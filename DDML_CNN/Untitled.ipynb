{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.23) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.FashionMNIST(root=\"data/fashion-mnist\", train=True, transform=transform, download=False)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.FashionMNIST(root=\"data/fashion-mnist\", train=False, transform=transform, download=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDMLNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DDMLNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=2), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(-1, 16 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DDMLNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,     0] loss: 0.023\n",
      "[0,   100] loss: 2.299\n",
      "[0,   200] loss: 2.287\n",
      "[0,   300] loss: 2.275\n",
      "[0,   400] loss: 2.206\n",
      "[0,   500] loss: 1.841\n",
      "[0,   600] loss: 1.403\n",
      "[0,   700] loss: 1.262\n",
      "[0,   800] loss: 1.176\n",
      "[0,   900] loss: 1.105\n",
      "[0,  1000] loss: 1.022\n",
      "[0,  1100] loss: 1.095\n",
      "[0,  1200] loss: 1.054\n",
      "[0,  1300] loss: 1.000\n",
      "[0,  1400] loss: 0.884\n",
      "[0,  1500] loss: 1.006\n",
      "[0,  1600] loss: 0.774\n",
      "[0,  1700] loss: 0.812\n",
      "[0,  1800] loss: 0.783\n",
      "[0,  1900] loss: 0.901\n",
      "[0,  2000] loss: 0.734\n",
      "[0,  2100] loss: 0.803\n",
      "[0,  2200] loss: 0.733\n",
      "[0,  2300] loss: 0.848\n",
      "[0,  2400] loss: 0.818\n",
      "[0,  2500] loss: 0.749\n",
      "[0,  2600] loss: 0.886\n",
      "[0,  2700] loss: 0.711\n",
      "[0,  2800] loss: 0.698\n",
      "[0,  2900] loss: 0.734\n",
      "[0,  3000] loss: 0.642\n",
      "[0,  3100] loss: 0.758\n",
      "[0,  3200] loss: 0.695\n",
      "[0,  3300] loss: 0.646\n",
      "[0,  3400] loss: 0.691\n",
      "[0,  3500] loss: 0.704\n",
      "[0,  3600] loss: 0.694\n",
      "[0,  3700] loss: 0.660\n",
      "[0,  3800] loss: 0.695\n",
      "[0,  3900] loss: 0.668\n",
      "[0,  4000] loss: 0.595\n",
      "[0,  4100] loss: 0.678\n",
      "[0,  4200] loss: 0.595\n",
      "[0,  4300] loss: 0.669\n",
      "[0,  4400] loss: 0.600\n",
      "[0,  4500] loss: 0.699\n",
      "[0,  4600] loss: 0.658\n",
      "[0,  4700] loss: 0.672\n",
      "[0,  4800] loss: 0.689\n",
      "[0,  4900] loss: 0.644\n",
      "[0,  5000] loss: 0.620\n",
      "[0,  5100] loss: 0.522\n",
      "[0,  5200] loss: 0.631\n",
      "[0,  5300] loss: 0.583\n",
      "[0,  5400] loss: 0.564\n",
      "[0,  5500] loss: 0.580\n",
      "[0,  5600] loss: 0.548\n",
      "[0,  5700] loss: 0.649\n",
      "[0,  5800] loss: 0.549\n",
      "[0,  5900] loss: 0.596\n",
      "[0,  6000] loss: 0.544\n",
      "[0,  6100] loss: 0.489\n",
      "[0,  6200] loss: 0.629\n",
      "[0,  6300] loss: 0.569\n",
      "[0,  6400] loss: 0.629\n",
      "[0,  6500] loss: 0.503\n",
      "[0,  6600] loss: 0.511\n",
      "[0,  6700] loss: 0.515\n",
      "[0,  6800] loss: 0.556\n",
      "[0,  6900] loss: 0.517\n",
      "[0,  7000] loss: 0.534\n",
      "[0,  7100] loss: 0.569\n",
      "[0,  7200] loss: 0.522\n",
      "[0,  7300] loss: 0.627\n",
      "[0,  7400] loss: 0.465\n",
      "[0,  7500] loss: 0.551\n",
      "[0,  7600] loss: 0.552\n",
      "[0,  7700] loss: 0.544\n",
      "[0,  7800] loss: 0.590\n",
      "[0,  7900] loss: 0.539\n",
      "[0,  8000] loss: 0.488\n",
      "[0,  8100] loss: 0.493\n",
      "[0,  8200] loss: 0.479\n",
      "[0,  8300] loss: 0.465\n",
      "[0,  8400] loss: 0.534\n",
      "[0,  8500] loss: 0.534\n",
      "[0,  8600] loss: 0.484\n",
      "[0,  8700] loss: 0.498\n",
      "[0,  8800] loss: 0.504\n",
      "[0,  8900] loss: 0.504\n",
      "[0,  9000] loss: 0.437\n",
      "[0,  9100] loss: 0.396\n",
      "[0,  9200] loss: 0.490\n",
      "[0,  9300] loss: 0.416\n",
      "[0,  9400] loss: 0.539\n",
      "[0,  9500] loss: 0.447\n",
      "[0,  9600] loss: 0.479\n",
      "[0,  9700] loss: 0.522\n",
      "[0,  9800] loss: 0.456\n",
      "[0,  9900] loss: 0.372\n",
      "[0, 10000] loss: 0.572\n",
      "[0, 10100] loss: 0.436\n",
      "[0, 10200] loss: 0.377\n",
      "[0, 10300] loss: 0.493\n",
      "[0, 10400] loss: 0.473\n",
      "[0, 10500] loss: 0.506\n",
      "[0, 10600] loss: 0.471\n",
      "[0, 10700] loss: 0.520\n",
      "[0, 10800] loss: 0.473\n",
      "[0, 10900] loss: 0.469\n",
      "[0, 11000] loss: 0.487\n",
      "[0, 11100] loss: 0.450\n",
      "[0, 11200] loss: 0.412\n",
      "[0, 11300] loss: 0.416\n",
      "[0, 11400] loss: 0.351\n",
      "[0, 11500] loss: 0.432\n",
      "[0, 11600] loss: 0.551\n",
      "[0, 11700] loss: 0.475\n",
      "[0, 11800] loss: 0.424\n",
      "[0, 11900] loss: 0.411\n",
      "[0, 12000] loss: 0.486\n",
      "[0, 12100] loss: 0.444\n",
      "[0, 12200] loss: 0.554\n",
      "[0, 12300] loss: 0.415\n",
      "[0, 12400] loss: 0.447\n",
      "[0, 12500] loss: 0.446\n",
      "[0, 12600] loss: 0.440\n",
      "[0, 12700] loss: 0.422\n",
      "[0, 12800] loss: 0.428\n",
      "[0, 12900] loss: 0.491\n",
      "[0, 13000] loss: 0.442\n",
      "[0, 13100] loss: 0.441\n",
      "[0, 13200] loss: 0.485\n",
      "[0, 13300] loss: 0.452\n",
      "[0, 13400] loss: 0.394\n",
      "[0, 13500] loss: 0.404\n",
      "[0, 13600] loss: 0.307\n",
      "[0, 13700] loss: 0.412\n",
      "[0, 13800] loss: 0.484\n",
      "[0, 13900] loss: 0.446\n",
      "[0, 14000] loss: 0.421\n",
      "[0, 14100] loss: 0.412\n",
      "[0, 14200] loss: 0.436\n",
      "[0, 14300] loss: 0.489\n",
      "[0, 14400] loss: 0.442\n",
      "[0, 14500] loss: 0.459\n",
      "[0, 14600] loss: 0.461\n",
      "[0, 14700] loss: 0.415\n",
      "[0, 14800] loss: 0.314\n",
      "[0, 14900] loss: 0.414\n",
      "[1,     0] loss: 0.003\n",
      "[1,   100] loss: 0.440\n",
      "[1,   200] loss: 0.479\n",
      "[1,   300] loss: 0.421\n",
      "[1,   400] loss: 0.428\n",
      "[1,   500] loss: 0.446\n",
      "[1,   600] loss: 0.369\n",
      "[1,   700] loss: 0.365\n",
      "[1,   800] loss: 0.409\n",
      "[1,   900] loss: 0.368\n",
      "[1,  1000] loss: 0.397\n",
      "[1,  1100] loss: 0.400\n",
      "[1,  1200] loss: 0.417\n",
      "[1,  1300] loss: 0.358\n",
      "[1,  1400] loss: 0.407\n",
      "[1,  1500] loss: 0.377\n",
      "[1,  1600] loss: 0.415\n",
      "[1,  1700] loss: 0.410\n",
      "[1,  1800] loss: 0.342\n",
      "[1,  1900] loss: 0.282\n",
      "[1,  2000] loss: 0.349\n",
      "[1,  2100] loss: 0.390\n",
      "[1,  2200] loss: 0.341\n",
      "[1,  2300] loss: 0.452\n",
      "[1,  2400] loss: 0.430\n",
      "[1,  2500] loss: 0.431\n",
      "[1,  2600] loss: 0.401\n",
      "[1,  2700] loss: 0.388\n",
      "[1,  2800] loss: 0.383\n",
      "[1,  2900] loss: 0.334\n",
      "[1,  3000] loss: 0.368\n",
      "[1,  3100] loss: 0.354\n",
      "[1,  3200] loss: 0.349\n",
      "[1,  3300] loss: 0.372\n",
      "[1,  3400] loss: 0.430\n",
      "[1,  3500] loss: 0.387\n",
      "[1,  3600] loss: 0.390\n",
      "[1,  3700] loss: 0.428\n",
      "[1,  3800] loss: 0.380\n",
      "[1,  3900] loss: 0.370\n",
      "[1,  4000] loss: 0.375\n",
      "[1,  4100] loss: 0.333\n",
      "[1,  4200] loss: 0.409\n",
      "[1,  4300] loss: 0.398\n",
      "[1,  4400] loss: 0.340\n",
      "[1,  4500] loss: 0.390\n",
      "[1,  4600] loss: 0.402\n",
      "[1,  4700] loss: 0.375\n",
      "[1,  4800] loss: 0.338\n",
      "[1,  4900] loss: 0.352\n",
      "[1,  5000] loss: 0.375\n",
      "[1,  5100] loss: 0.417\n",
      "[1,  5200] loss: 0.440\n",
      "[1,  5300] loss: 0.299\n",
      "[1,  5400] loss: 0.484\n",
      "[1,  5500] loss: 0.380\n",
      "[1,  5600] loss: 0.375\n",
      "[1,  5700] loss: 0.347\n",
      "[1,  5800] loss: 0.429\n",
      "[1,  5900] loss: 0.415\n",
      "[1,  6000] loss: 0.356\n",
      "[1,  6100] loss: 0.394\n",
      "[1,  6200] loss: 0.400\n",
      "[1,  6300] loss: 0.365\n",
      "[1,  6400] loss: 0.331\n",
      "[1,  6500] loss: 0.366\n",
      "[1,  6600] loss: 0.388\n",
      "[1,  6700] loss: 0.361\n",
      "[1,  6800] loss: 0.360\n",
      "[1,  6900] loss: 0.392\n",
      "[1,  7000] loss: 0.387\n",
      "[1,  7100] loss: 0.364\n",
      "[1,  7200] loss: 0.443\n",
      "[1,  7300] loss: 0.358\n",
      "[1,  7400] loss: 0.371\n",
      "[1,  7500] loss: 0.348\n",
      "[1,  7600] loss: 0.432\n",
      "[1,  7700] loss: 0.318\n",
      "[1,  7800] loss: 0.358\n",
      "[1,  7900] loss: 0.409\n",
      "[1,  8000] loss: 0.429\n",
      "[1,  8100] loss: 0.378\n",
      "[1,  8200] loss: 0.451\n",
      "[1,  8300] loss: 0.365\n",
      "[1,  8400] loss: 0.379\n",
      "[1,  8500] loss: 0.401\n",
      "[1,  8600] loss: 0.382\n",
      "[1,  8700] loss: 0.401\n",
      "[1,  8800] loss: 0.393\n",
      "[1,  8900] loss: 0.376\n",
      "[1,  9000] loss: 0.280\n",
      "[1,  9100] loss: 0.406\n",
      "[1,  9200] loss: 0.357\n",
      "[1,  9300] loss: 0.246\n",
      "[1,  9400] loss: 0.383\n",
      "[1,  9500] loss: 0.394\n",
      "[1,  9600] loss: 0.448\n",
      "[1,  9700] loss: 0.281\n",
      "[1,  9800] loss: 0.386\n",
      "[1,  9900] loss: 0.425\n",
      "[1, 10000] loss: 0.349\n",
      "[1, 10100] loss: 0.271\n",
      "[1, 10200] loss: 0.356\n",
      "[1, 10300] loss: 0.417\n",
      "[1, 10400] loss: 0.334\n",
      "[1, 10500] loss: 0.299\n",
      "[1, 10600] loss: 0.309\n",
      "[1, 10700] loss: 0.355\n",
      "[1, 10800] loss: 0.325\n",
      "[1, 10900] loss: 0.348\n",
      "[1, 11000] loss: 0.341\n",
      "[1, 11100] loss: 0.339\n",
      "[1, 11200] loss: 0.291\n",
      "[1, 11300] loss: 0.350\n",
      "[1, 11400] loss: 0.369\n",
      "[1, 11500] loss: 0.330\n",
      "[1, 11600] loss: 0.297\n",
      "[1, 11700] loss: 0.283\n",
      "[1, 11800] loss: 0.398\n",
      "[1, 11900] loss: 0.352\n",
      "[1, 12000] loss: 0.397\n",
      "[1, 12100] loss: 0.321\n",
      "[1, 12200] loss: 0.332\n",
      "[1, 12300] loss: 0.374\n",
      "[1, 12400] loss: 0.350\n",
      "[1, 12500] loss: 0.414\n",
      "[1, 12600] loss: 0.346\n",
      "[1, 12700] loss: 0.281\n",
      "[1, 12800] loss: 0.350\n",
      "[1, 12900] loss: 0.343\n",
      "[1, 13000] loss: 0.268\n",
      "[1, 13100] loss: 0.389\n",
      "[1, 13200] loss: 0.326\n",
      "[1, 13300] loss: 0.402\n",
      "[1, 13400] loss: 0.391\n",
      "[1, 13500] loss: 0.300\n",
      "[1, 13600] loss: 0.308\n",
      "[1, 13700] loss: 0.339\n",
      "[1, 13800] loss: 0.343\n",
      "[1, 13900] loss: 0.310\n",
      "[1, 14000] loss: 0.347\n",
      "[1, 14100] loss: 0.384\n",
      "[1, 14200] loss: 0.325\n",
      "[1, 14300] loss: 0.356\n",
      "[1, 14400] loss: 0.307\n",
      "[1, 14500] loss: 0.400\n",
      "[1, 14600] loss: 0.412\n",
      "[1, 14700] loss: 0.312\n",
      "[1, 14800] loss: 0.323\n",
      "[1, 14900] loss: 0.327\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch, i, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "currcet = 0\n",
    "\n",
    "for inputs, labels in testloader:\n",
    "    outputs = net(inputs)\n",
    "    value, result = torch.max(outputs, dim=1)\n",
    "\n",
    "    if result == labels:\n",
    "        currcet += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8744"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currcet/len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140061776948320"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(p[5].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2503,  0.6235,  0.3977, -0.9062,  3.1390, -0.3585, -0.3160,\n",
       "         1.2803, -1.9810, -0.2359, -0.5886, -0.3396,  0.1739, -0.4158,\n",
       "        -0.3605, -1.3266, -0.7727, -1.4952,  0.4273,  0.3919, -1.7949,\n",
       "         0.5489, -2.8924, -0.2457, -0.6428, -1.2991, -0.7892,  0.7772,\n",
       "         0.8509,  0.4290,  0.5687,  1.2908, -0.7518,  0.6406, -0.4864,\n",
       "         1.3753,  1.7053,  1.5062, -2.1529, -0.2778, -1.4133, -1.0603,\n",
       "        -1.0310,  0.6597, -0.8367, -1.1041, -0.5733,  1.0010,  1.1177,\n",
       "        -1.0557, -1.1679,  0.0086, -0.9557, -0.5922,  0.6309,  1.7029,\n",
       "         0.2819,  0.8734, -0.4209,  1.0276, -1.1666,  0.3717, -1.3816,\n",
       "         0.7741, -0.4853,  2.1810, -0.0510,  0.3209, -0.1571,  0.5306,\n",
       "         1.2918,  1.0591, -1.3354,  0.4622, -0.8600, -0.8014, -1.0855,\n",
       "         0.2888,  0.0252, -0.4255,  0.8408, -0.2051,  1.4430,  0.4288])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[5].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fc1 = list(net.fc1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140061721570904"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(p_fc1[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2503,  0.6235,  0.3977, -0.9062,  3.1390, -0.3585, -0.3160,\n",
       "         1.2803, -1.9810, -0.2359, -0.5886, -0.3396,  0.1739, -0.4158,\n",
       "        -0.3605, -1.3266, -0.7727, -1.4952,  0.4273,  0.3919, -1.7949,\n",
       "         0.5489, -2.8924, -0.2457, -0.6428, -1.2991, -0.7892,  0.7772,\n",
       "         0.8509,  0.4290,  0.5687,  1.2908, -0.7518,  0.6406, -0.4864,\n",
       "         1.3753,  1.7053,  1.5062, -2.1529, -0.2778, -1.4133, -1.0603,\n",
       "        -1.0310,  0.6597, -0.8367, -1.1041, -0.5733,  1.0010,  1.1177,\n",
       "        -1.0557, -1.1679,  0.0086, -0.9557, -0.5922,  0.6309,  1.7029,\n",
       "         0.2819,  0.8734, -0.4209,  1.0276, -1.1666,  0.3717, -1.3816,\n",
       "         0.7741, -0.4853,  2.1810, -0.0510,  0.3209, -0.1571,  0.5306,\n",
       "         1.2918,  1.0591, -1.3354,  0.4622, -0.8600, -0.8014, -1.0855,\n",
       "         0.2888,  0.0252, -0.4255,  0.8408, -0.2051,  1.4430,  0.4288])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_fc1[1].data = torch.randn(84)\n",
    "p_fc1[1].data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
